{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQAR DiT-XL Benchmark\n",
    "\n",
    "Test the DQARAttentionProcessor on DiT-XL-2-256 with real attention weight capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "!pip install -q torch diffusers accelerate transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone DQAR repo (or upload the src folder)\n",
    "!git clone https://github.com/YOUR_USERNAME/DQAR.git 2>/dev/null || (cd DQAR && git pull)\n",
    "import sys\n",
    "sys.path.insert(0, 'DQAR/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from diffusers import DiTPipeline, DPMSolverMultistepScheduler\n",
    "\n",
    "# Check GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DiT-XL-2-256\n",
    "print(\"Loading DiT-XL-2-256...\")\n",
    "pipe = DiTPipeline.from_pretrained(\n",
    "    \"facebook/DiT-XL-2-256\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe = pipe.to(device)\n",
    "print(f\"Loaded! Transformer has {len(pipe.transformer.transformer_blocks)} blocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import DQAR and patch the pipeline\n",
    "from dqar import DQARController, DQARConfig\n",
    "from dqar.dit_wrapper import patch_dit_pipeline, get_dit_layer_count\n",
    "\n",
    "# Patch pipeline with DQAR processors\n",
    "pipe = patch_dit_pipeline(pipe)\n",
    "num_layers = get_dit_layer_count(pipe)\n",
    "print(f\"Patched {num_layers} attention layers with DQARAttentionProcessor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create configs\n",
    "def make_baseline_config():\n",
    "    \"\"\"Config that prevents ALL reuse.\"\"\"\n",
    "    cfg = DQARConfig()\n",
    "    cfg.gate.min_step = 9999\n",
    "    cfg.gate.entropy_threshold = 0.0\n",
    "    cfg.gate.min_probability = 1.0\n",
    "    cfg.scheduler.max_gap = 0\n",
    "    cfg.scheduler.max_reuse_per_block = 0\n",
    "    return cfg\n",
    "\n",
    "def make_static_config():\n",
    "    \"\"\"Config that always reuses if cached.\"\"\"\n",
    "    cfg = DQARConfig()\n",
    "    cfg.gate.min_step = 0\n",
    "    cfg.gate.entropy_threshold = 1e9\n",
    "    cfg.gate.min_probability = 0.0\n",
    "    cfg.gate.snr_range = (0.0, 1e9)\n",
    "    cfg.gate.cooldown_steps = 0\n",
    "    cfg.scheduler.max_gap = 50\n",
    "    cfg.scheduler.max_reuse_per_block = 50\n",
    "    return cfg\n",
    "\n",
    "def make_dqar_config(entropy_threshold=3.0):\n",
    "    \"\"\"Config with entropy-gated reuse.\"\"\"\n",
    "    cfg = DQARConfig()\n",
    "    cfg.gate.min_step = 0\n",
    "    cfg.gate.entropy_threshold = entropy_threshold\n",
    "    cfg.gate.min_probability = 0.0\n",
    "    cfg.gate.snr_range = (0.0, 1e9)\n",
    "    cfg.gate.cooldown_steps = 0\n",
    "    cfg.scheduler.max_gap = 10\n",
    "    cfg.scheduler.max_reuse_per_block = 10\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark function\n",
    "def benchmark_config(pipe, config, class_labels, num_steps=25, num_runs=3, seed=42):\n",
    "    \"\"\"Benchmark a configuration and return stats.\"\"\"\n",
    "    times = []\n",
    "    reuse_counts = []\n",
    "    \n",
    "    for run in range(num_runs):\n",
    "        # Create fresh controller each run\n",
    "        controller = DQARController(num_layers=num_layers, config=config)\n",
    "        \n",
    "        # Warmup CUDA\n",
    "        if run == 0:\n",
    "            torch.cuda.synchronize()\n",
    "        \n",
    "        generator = torch.Generator(device=device).manual_seed(seed + run)\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        start = time.perf_counter()\n",
    "        \n",
    "        output = pipe(\n",
    "            class_labels=class_labels,\n",
    "            num_inference_steps=num_steps,\n",
    "            generator=generator,\n",
    "            controller=controller,\n",
    "            output_type=\"pt\",\n",
    "        )\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        elapsed = time.perf_counter() - start\n",
    "        \n",
    "        times.append(elapsed)\n",
    "        reuse_counts.append(controller.get_reuse_count())\n",
    "        \n",
    "        print(f\"  Run {run+1}: {elapsed:.2f}s, reuse={controller.get_reuse_count()}\")\n",
    "    \n",
    "    return {\n",
    "        \"avg_time\": np.mean(times),\n",
    "        \"std_time\": np.std(times),\n",
    "        \"avg_reuse\": np.mean(reuse_counts),\n",
    "        \"std_reuse\": np.std(reuse_counts),\n",
    "        \"image\": output.images[0] if hasattr(output, 'images') else None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run benchmarks\n",
    "class_labels = [207]  # Golden retriever\n",
    "num_steps = 25\n",
    "num_runs = 3\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"BASELINE (no reuse)\")\n",
    "print(\"=\"*50)\n",
    "baseline = benchmark_config(pipe, make_baseline_config(), class_labels, num_steps, num_runs)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"STATIC (always reuse)\")\n",
    "print(\"=\"*50)\n",
    "static = benchmark_config(pipe, make_static_config(), class_labels, num_steps, num_runs)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DQAR (entropy threshold=3.0)\")\n",
    "print(\"=\"*50)\n",
    "dqar_3 = benchmark_config(pipe, make_dqar_config(3.0), class_labels, num_steps, num_runs)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DQAR (entropy threshold=4.0)\")\n",
    "print(\"=\"*50)\n",
    "dqar_4 = benchmark_config(pipe, make_dqar_config(4.0), class_labels, num_steps, num_runs)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DQAR (entropy threshold=5.0)\")\n",
    "print(\"=\"*50)\n",
    "dqar_5 = benchmark_config(pipe, make_dqar_config(5.0), class_labels, num_steps, num_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Config':<20} {'Time (s)':<15} {'Reuse Events':<15} {'Speedup':<10}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Baseline':<20} {baseline['avg_time']:.2f} ± {baseline['std_time']:.2f}   {baseline['avg_reuse']:.0f}             1.00x\")\n",
    "print(f\"{'Static':<20} {static['avg_time']:.2f} ± {static['std_time']:.2f}   {static['avg_reuse']:.0f}           {baseline['avg_time']/static['avg_time']:.2f}x\")\n",
    "print(f\"{'DQAR τ=3.0':<20} {dqar_3['avg_time']:.2f} ± {dqar_3['std_time']:.2f}   {dqar_3['avg_reuse']:.0f}           {baseline['avg_time']/dqar_3['avg_time']:.2f}x\")\n",
    "print(f\"{'DQAR τ=4.0':<20} {dqar_4['avg_time']:.2f} ± {dqar_4['std_time']:.2f}   {dqar_4['avg_reuse']:.0f}           {baseline['avg_time']/dqar_4['avg_time']:.2f}x\")\n",
    "print(f\"{'DQAR τ=5.0':<20} {dqar_5['avg_time']:.2f} ± {dqar_5['std_time']:.2f}   {dqar_5['avg_reuse']:.0f}           {baseline['avg_time']/dqar_5['avg_time']:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "configs = ['Baseline', 'Static', 'DQAR\\nτ=3.0', 'DQAR\\nτ=4.0', 'DQAR\\nτ=5.0']\n",
    "times = [baseline['avg_time'], static['avg_time'], dqar_3['avg_time'], dqar_4['avg_time'], dqar_5['avg_time']]\n",
    "time_errs = [baseline['std_time'], static['std_time'], dqar_3['std_time'], dqar_4['std_time'], dqar_5['std_time']]\n",
    "reuse = [baseline['avg_reuse'], static['avg_reuse'], dqar_3['avg_reuse'], dqar_4['avg_reuse'], dqar_5['avg_reuse']]\n",
    "\n",
    "colors = ['#4C72B0', '#55A868', '#C44E52', '#8172B2', '#CCB974']\n",
    "x = np.arange(len(configs))\n",
    "\n",
    "# Plot 1: Inference Time\n",
    "bars1 = axes[0].bar(x, times, yerr=time_errs, capsize=5, color=colors)\n",
    "axes[0].set_ylabel('Time (seconds)', fontsize=12)\n",
    "axes[0].set_title('Inference Time (25 steps)', fontsize=13)\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(configs)\n",
    "axes[0].bar_label(bars1, fmt='%.2f')\n",
    "\n",
    "# Plot 2: Reuse Events\n",
    "bars2 = axes[1].bar(x, reuse, color=colors)\n",
    "axes[1].set_ylabel('Reuse Events', fontsize=12)\n",
    "axes[1].set_title('Attention Reuse Count', fontsize=13)\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(configs)\n",
    "axes[1].bar_label(bars2, fmt='%.0f')\n",
    "\n",
    "fig.suptitle('DQAR DiT-XL-2-256 Benchmark', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('dit_xl_benchmark_results.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample images\n",
    "from PIL import Image\n",
    "\n",
    "# Generate comparison images\n",
    "print(\"Generating comparison images...\")\n",
    "\n",
    "# Baseline image\n",
    "controller_base = DQARController(num_layers=num_layers, config=make_baseline_config())\n",
    "generator = torch.Generator(device=device).manual_seed(42)\n",
    "img_baseline = pipe(\n",
    "    class_labels=[207],\n",
    "    num_inference_steps=50,\n",
    "    generator=generator,\n",
    "    controller=controller_base,\n",
    ").images[0]\n",
    "\n",
    "# DQAR image (same seed)\n",
    "controller_dqar = DQARController(num_layers=num_layers, config=make_dqar_config(4.0))\n",
    "generator = torch.Generator(device=device).manual_seed(42)\n",
    "img_dqar = pipe(\n",
    "    class_labels=[207],\n",
    "    num_inference_steps=50,\n",
    "    generator=generator,\n",
    "    controller=controller_dqar,\n",
    ").images[0]\n",
    "\n",
    "print(f\"Baseline reuse: {controller_base.get_reuse_count()}\")\n",
    "print(f\"DQAR reuse: {controller_dqar.get_reuse_count()}\")\n",
    "\n",
    "# Display side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(img_baseline)\n",
    "axes[0].set_title(f'Baseline (reuse=0)', fontsize=12)\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(img_dqar)\n",
    "axes[1].set_title(f'DQAR τ=4.0 (reuse={controller_dqar.get_reuse_count()})', fontsize=12)\n",
    "axes[1].axis('off')\n",
    "\n",
    "fig.suptitle('DiT-XL-2-256: Golden Retriever (class 207)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('dit_xl_comparison_results.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entropy threshold sweep\n",
    "print(\"Running entropy threshold sweep...\")\n",
    "thresholds = [2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 6.0]\n",
    "sweep_results = []\n",
    "\n",
    "for thresh in thresholds:\n",
    "    cfg = make_dqar_config(thresh)\n",
    "    controller = DQARController(num_layers=num_layers, config=cfg)\n",
    "    generator = torch.Generator(device=device).manual_seed(42)\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    output = pipe(\n",
    "        class_labels=[207],\n",
    "        num_inference_steps=25,\n",
    "        generator=generator,\n",
    "        controller=controller,\n",
    "        output_type=\"pt\",\n",
    "    )\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    elapsed = time.perf_counter() - start\n",
    "    \n",
    "    sweep_results.append({\n",
    "        \"threshold\": thresh,\n",
    "        \"time\": elapsed,\n",
    "        \"reuse\": controller.get_reuse_count(),\n",
    "    })\n",
    "    print(f\"τ={thresh:.1f}: time={elapsed:.2f}s, reuse={controller.get_reuse_count()}\")\n",
    "\n",
    "# Plot sweep\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "threshs = [r['threshold'] for r in sweep_results]\n",
    "times = [r['time'] for r in sweep_results]\n",
    "reuses = [r['reuse'] for r in sweep_results]\n",
    "\n",
    "axes[0].plot(threshs, reuses, 'o-', color='#C44E52', linewidth=2, markersize=8)\n",
    "axes[0].axhline(y=baseline['avg_reuse'], color='#4C72B0', linestyle='--', label='Baseline')\n",
    "axes[0].set_xlabel('Entropy Threshold', fontsize=12)\n",
    "axes[0].set_ylabel('Reuse Events', fontsize=12)\n",
    "axes[0].set_title('Threshold vs Reuse Count', fontsize=13)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(threshs, times, 'o-', color='#C44E52', linewidth=2, markersize=8)\n",
    "axes[1].axhline(y=baseline['avg_time'], color='#4C72B0', linestyle='--', label='Baseline')\n",
    "axes[1].set_xlabel('Entropy Threshold', fontsize=12)\n",
    "axes[1].set_ylabel('Time (seconds)', fontsize=12)\n",
    "axes[1].set_title('Threshold vs Inference Time', fontsize=13)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "fig.suptitle('DQAR Entropy Threshold Sweep (DiT-XL)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('dit_xl_sweep_results.png', dpi=150)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
